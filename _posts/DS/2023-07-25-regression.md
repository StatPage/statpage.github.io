---
layout: single
title:  "회귀 분석을 위한 기초통계학"
toc: true
toc_sticky: true
# categories: [regression analysis]
# tags: [통계학, 모집단, 표본, 확률변수, 분산, 분포, 회귀 분석, 계량경제학]
---

# 데이터 사이언스를 위한 회귀분석 정리 1편: 평균부터 모형까지

![image](https://github.com/StatPage/blog-images/assets/61931924/8bdb6479-d99e-423e-9fd2-70d1c82f8ebe){: .align-center}{: width="75%" height="75%"}

## 통계학이란 무엇인가?   
> `불확실성`을 다루는 학문이다.

   
불확실성이란 것 또한 데이터가 쌓이다보면 불확실성이 줄어든다.  
   
그러나 모든 데이터를 살펴볼 수 없기 때문에 통계학에서는 모집단에서 표본을 random하고 추출해 조사가 왜곡되는 것을 방지한다. (임의 실험)

-   [모집단](https://www.google.com/search?q=%EB%AA%A8%EC%A7%91%EB%8B%A8&oq=%EB%AA%A8%EC%A7%91%EB%8B%A8&aqs=chrome..69i57j0i512l9.1085j0j7&sourceid=chrome&ie=UTF-8)
-   [표본](https://www.google.com/search?q=%ED%91%9C%EB%B3%B8&oq=%ED%91%9C%EB%B3%B8&aqs=chrome..69i57j0i512l9.713j0j9&sourceid=chrome&ie=UTF-8)

표본을 얻었다면 이를 통해 모집단의 ~~평균 $\mu$~~과 ~~분산 $\sigma^2$~~를 추정한다. 식은 다음과 같다.

$$\hat{\mu} = \frac{1}{n} \sum y_i $$

$$\hat{\sigma} = \frac{1}{n-1} \sum (y_i - \hat{\mu})^2$$

조사를 해서 데이터를 얻으면 식에 대입해서 추정치를 구할 수 있다.

<br/>

### 추정치(estimate)와 추정량(estimator)을 구분하자

`추정량(estimator)`는 공식을 의미하며 실제 데이터를 대입하기 전의 확률변수이다. 추정치는 데이터를 공식에 대입해 얻은 실현치를 의미한다.  
 

> 추정량 estimator에 대해서 조금만 더 생각을 해보자. 확률변수란 말은 이 또한 분포를 따른다는 것이고 불확실성을 포함하고 있다는 의미다. 불확실성을 포함하면 어떤 걸 유추할 수 있을까? 

   
맨 처음 언급했던 것처럼 동일한 모집단에서 데이터의 수가 증가할 수록 불확실성은 감소하며 반대로 데이터의 수가 감소할수록 변수의 불확실성은 증가하게 된다.

확률변수라면 평균을 어떻게 구할까?  
 

> 확률변수가 취할 수 있는 모든 값들의 가중 평균인 기대값을 계산하면 된다. 확률변수의 불확실성을 나타내는 분산은 다음과 같이 알려진 식에 대입해서 구한다.

   
$$ E(y_i) = \mu $$

$$Var(y_i) = \sigma^2 $$

<br/>

![image](https://github.com/StatPage/blog-images/assets/61931924/788bbdc6-720b-4b4c-a398-5b8848bc3578){: .align-center}

## 데이터의 종류: 이산형과 연속형

위의 ~~$E(y_i)$~~를 어떻게 구하는지 식이 쓰여있지 않다. ~~$y_i$~~가 연속형일 때는 아래와 같이 구한다.

$$E(y_i) = \int f(y) y_i dy$$

이는 ~~$f(y)$~~가 ~~$y$~~가 발생할 확률(가중치)로써 곱해졌다고 보면 된다. ~~$y$~~ 값으로 측정되는 비율이 분명 다를 테니까 이를 평균으로 구할 때도 반영해주는 것(가중평균)이다.  
   
이번에는 ~~$y_i$~~가 이산형일 때를 구해보자.

$$E(y_i) = \sum Pr(y_i = y) y_i $$

뭐가 달라졌을까? 각 ~~$y_i$~~값의 가중치 부분과 summation 부분이 다른 것이지 기본적인 구조인 가중치 곱셈과 이를 모두 합산한다는 것은 동일하다. 참고로 분산의 식 또한 동일한 방식이다. 

<br/>
식에 대해서 한 가지 생각을 해보자면 기댓값을 구하기 위해서 각 ~~$y$~~값의 확률을 가중치로 곱해줬듯이 분산 또한 편차의 제곱 ~~$(Y - E(Y))^2$~~을 구할 때 ~~$y$~~값의 확률을 곱해준다는 것이다. 편차의 제곱도 영향력이 다르다고 생각해볼 수 있을 것 같다.

- 연속형 데이터의 분산: $Var(Y) = \int (Y - E(Y))^2 f(y) dy$
- 이산형 데이터의 분산: $Var(Y) = \sum (Y - E(Y))^2 Pr(Y=y)$

<br/>

## 데이터 $y$가 아닌 추정량 $\hat{\mu}$의 분산도

위의 쓴 수식은 데이터 자체의 분산을 본 것이었다. 이제는 추정량 estimator의 분산 ~~$Var(\hat{\mu})$~~을 봐야 한다. 왜냐하면 추정을 하는데 불확실성은 크면 클수록 안 좋을 것이기 때문이다. 

### 추정량 Estimator는 어디까지 정확해야 할까?

추정량의 분산에 가기 전에 우선 추정량의 기댓값에 대해서 한 번 생각해보자. 위에서 구한 기댓값의 경우에는 데이터 $y$의 기댓값 $E(y)$을 구한 것이었다. 모집단의 평균 $\mu$의 추정량을 $\hat{\mu} = \bar{y}$라고 했을 때, 기댓값을 구해보겠다. 아래의 식과 같이 추정량의 기댓값이 모집단의 평균 $\mu$와 동일하면 `불편추정량(unbiased estimator)`라고 한다. 분산도 가능하지만 이거는 회귀분석 부분에서 한 번 다루겠다.

$$E(\bar{y}) = \underset{n \rightarrow \infty}{\lim} \frac{\sum \bar{y}_i }{J} = \frac{J \mu}{J} = \mu$$


![image](https://github.com/StatPage/blog-images/assets/61931924/8a44a11b-b316-4b4f-af96-619140177f9e){: .align-center}


> 추정량 estimator들의 기댓값이 모두 모수의 평균과 동일할 때 estimator의 분산은 더 작은 쪽(빨간색)이 선호된다.

왜냐하면 반복적인 표본 추출(random sampling)이 불가능한 경우가 있기도 하며 다른 추정치보다 더 정확하게 추정을 할 수 있는 확률이 상승하기 때문이다. 참고로 불확실성을 나타내는 분산의 역수를 추정의 정확도라고 한다. 

> 새로운 사업을 했을 때 비용이 평균 100만원 든다고 하면서 최소 1만원에서 199만원까지 든다고 하면 이건 예상이 의미가 거의 없게 되는 것 같다. 반대로 90만원에서 110만원 정도 든다고 하면 100만원에서 가능하면 110만원까지 준비하고 사업을 시작할 수 있을 것이다.


![image](https://github.com/StatPage/blog-images/assets/61931924/c21364ff-3f43-4bb0-8947-0720969e9b4f){: .align-center}

<br/>

## 모형 세우기

앞서 배운 기댓값과 분산을 배운 이유는 모델을 만들기 위해서다. 모델을 세우는 이유는? 자연 현상에 대해 더 잘 이해하면 현명한 판단을 내릴 수 있으니까. 아래와 같은 간단한 모델을 세워보자.

$$y_i = \mu + \epsilon_i$$

where $E(e_i) = 0 \quad \forall i$,  $E(e_i^2) = \sigma^2 \quad \forall i$

   
데이터 ~~$y_i$~~는 평균 ~~$\mu$~~로부터 랜덤하게 ~~$e_i$~~만큼 떨어져있다는 것을 의미한다. 말그대로 데이터에서 확실한 요소인 ~~$\mu$~~와 불확실한 요소인 ~~$\epsilon_i$~~를 분리해서 표현해줬다.


불확실한 요소인 ~~$e_i$~~는 데이터가 나오기 전까지 알 수가 없으니까 똑같이 확률변수이면서 기댓값과 분산을 가지고 있다. 그게 where 뒤에 나온 수식들이다.  
 

> $E(e_i) = 0$는 왜 성립할까?

   
데이터 ~~$y$~~가 원래 ~~$\mu$~~를 중심으로 분포해있기 때문에 그 중심을 ~~$\mu$~~에서 ~~$0$~~으로 옮긴 것 뿐이다. ~~$e_i$~~는 순수하게 불확실한 요소, 변동성만을 나타낸다는 것. 만약에 ~~$E(e_i) \neq 0$~~라면? 데이터에서 확실한 요소를 제대로 분리해내지 못했다는 의미이기도 할 것이다. ~~$e_i$~~는 정말 순수한 random인 변동성만을 나타내야 하지 모델의 구조를 바꿔버리면 안 되기 때문이다.

~~$E(e_i^2) = \sigma^2 \quad \forall i$~~는 분산을 의미하는데 모든 데이터에서 변동성이 그대로 유지된다는 것을 의미하며 $y_i$에서 평균만 이동하고 변동성을 그대로 가져온 것이기 때문에 $e_i$와 $y_i$의 변동성이 동일하다고 생각할 수 있다. ~~$E(e_i^2)$~~이 왜 분산인지는 아래의 식을 보면 된다.

$$ Var(e_i) = E \{ (e_i - E(e_i))^2 \} = E \{(e_i - 0)^2\}  = E (e^2_i) $$

<br/>

# 데이터 사이언스를 위한 회귀분석 정리 2편: OLS부터 불편추정량까지

앞 내용에서 평균과 분산에 대해 모형을 살펴봤다. 또한 어떤 식으로 평균과 분산을 추정하는지도 알게 됐다.

오늘은 어떻게 추정량 estimator를 세우는지 정리해보도록 하겠다.

![image](https://github.com/StatPage/blog-images/assets/61931924/2f091404-c4b0-426a-82be-eac8c251f9f9){: .align-center}{: width="75%" height="75%"}

## OLS

우선 다시 한 번 평균과 분산을 어떤 estimator로 추정하는지 확인하자.  

$$ \bar{y} = \frac{1}{n} \sum y_i $$  
$$ \hat{\sigma}^2 = \frac{1}{n-1} \sum (y_i - \bar{y})^2 $$  
 

> 이 공식들은 어떤 기준으로 나온 걸까? 정확히는 어떻게 유도가 됐을까?


정답부터 말하자면 이 식들은 표본의 평균과 표본의 분산이 모집단의 평균과 모집단의 분산에 가장 가까워지도록 `OLS(Ordinary Least Square)`라는 기준으로 유도되었다고 한다. 다음 식을 보자. $y_i$를 추정량 $\hat{\mu}$와 $\hat{e}$로 표현했다.  
   
$$y_i = \hat{\mu} + \hat{e}_i$$  

$y_i$와 $\hat{\mu}$는 실제 데이터와 추정한 데이터니까 이 둘의 차이가 가장 적도록 만들어 준다. 하지만 차이를 다 더해주면 0이 되니까 제곱합이 가장 적도록 만들어준다. 즉 $\sum \hat{e}^2$이 가장 적도록 만들어 주는 것이다.  
   
$$ \sum(y_i - \hat{\mu}) = \sum y_i - \sum \bar{y} = n \bar{y} - n \bar{y} = 0  $$  

$$ \underset{\mu}{\text{argmin}} \sum (y_i - \hat{\mu})^2 = \underset{\mu}{\text{argmin}} \sum \hat{e}_i^2 $$  
   
이 식을 최소로 만들어주는 $\hat{\mu}$는 공식을 $\mu$로 미분하면 쉽게 알 수 있다. 이 글에서는 흐름이 중요하니까 다 쓰지는 않겠다. 결과는 우리가 알고 있는 식이 나온다.  
   
$$ \hat{\mu} = \frac{\sum y_i}{n} $$  

이렇게 공식을 유도하는 방법을 `OLS`라고 부른다.  
   
이제는 공식을 검토할 차례다.  

<br/>

![image](https://github.com/StatPage/blog-images/assets/61931924/478d5d9b-8457-44ed-87bc-130ec55e82ec)

## Unbiased Estimator 불편추정량

### 평균의 불편추정량
  
 


> 공식을 검토한다는 것은 무슨 말일까? 왜 검토를 해야 할까?


   
우리가 공식을 이용하는 이유는 우리에게 도움이 돼기 때문이다. 이 공식들이 도움이 된다는 걸 데이터를 얻기 전에 어떻게 확인할 수 있을까? 앞서 모형을 세울 때 가정으로 세운 것이 만족하는지 보는 것이다.  
   
앞선 글에서 모형은 이렇게 세워졌다. 

$$y_i = \mu + e_i$$  

where $E(e_i) = 0 ~~ \forall i$ and $E(e_i^2) = \sigma^2 ~~ \forall i$  
   
저 모형의 가정은 where 뒤에 있는 두 공식 $E(e_i) = 0 ~~ \forall i$와 $E(e_i^2) = \sigma^2 ~~ \forall i$이다.  
   
우리가 구한 추정량 $\mu$가 맞다면 $\mu$를 통해서 얻은 $y - \hat{\mu} = e$를 저 공식들을 만족할 수 있을 것이다.


> 즉 모형을 세울 때 만든 가정들을 추정량이 맞는지 확인하면 우리의 공식이 맞다고 생각할 수 있는 것이다.

   
결과만 써보자면, (과정은 직접 해봐도 좋고 책에 나와있으니까 참고한 책에 잘 정리돼있다.)  

$$E(\hat{\mu}) = \mu  \Leftrightarrow E(\hat{e}) = 0$$  

이 결과를 `불편추정량(Unbiased Estimator)`라고 한다. 모형을 세울 때의 가정을 만족했으니 올바른 추정이라고 할 수 있는 것이다.

<br/>

![image](https://github.com/StatPage/blog-images/assets/61931924/6ac304a4-8268-4dc5-9341-5f893b55d9a7)

## 분산의 불편추정량

### 모평균 $\mu$를 모를 때

이제는 분산 $\sigma^2$도 추정을 해야 한다. $\sigma^2$을 추정해야 할 때는 모평균 $\mu$를 알 때와 모를 때를 구분해서 식을 구할 수 있다. 그러나 우리는 보통 모평균에 대해 모른다. 그래서 모평균을 모르는 경우에 대해서 어떻게 분산의 추정량을 구하는지 유도를 하고 그 결과에서 모평균을 알 때 어떻게 유도할 수 있는지 역순으로 정리해보겠다.  
(이해가 필요한 정리들은 직접 수식을 써보지만 단순히 수식을 전개하거나 책을 찾아보면 되는 식들은 생략.)  
   
먼저 $E(e_i^2) = \sigma^2 ~~ \forall i$라는 가정에서 출발해보겠다.  

$$\begin{align*}  
n \sigma^2 = E( \sum e_i^2 ) &= E(\sum (y_i - \mu)^2) \because E(e_i^2) = \sigma^2 \\  
&= E( \sum \{ ( y_i - \hat{\mu} + \hat{\mu} - \mu ) \}^2) \\  
&= E( \sum (y_i - \hat{\mu}) ^2 + \sum (\hat{\mu} - \mu )^2 ) \quad \because \sum (y_i - \hat{\mu})(\hat{\mu} - \mu) = 0\\  
&= E( \sum (y_i - \hat{\mu}) ^2 + n (\hat{\mu} - \mu )^2 )\\  
&= E( \sum (\hat{e}_i^2)) + n Var(\hat{\mu})\\  
E( \sum (\hat{e}_i^2)) &= n \sigma^2 - n Var(\hat{\mu})  
\end {align*}$$  

여기서 식을 더 전개하기 위해서는 불편추정량 $\hat{\mu}$의 분산을 알아야 한다. 이 식 또한 식을 전개하거나 책을 참고해서 보면 구할 수 있는 값이다. 우선 결과는 **$Var(\hat{\mu}) = \frac{\sigma^2}{n}$**이다. 식을 이어가보자.  

$$  
\begin{align*}  
E(\sum (\hat{e}_i^2)) &= n \sigma^2+ n \frac{\sigma^2}{n}\\  
E(\sum (\hat{e}_i^2)) &= (n-1) \sigma^2 \\  
E(\frac{ \sum \hat{e}_i^2}{n-1}) &= \sigma^2 \\  
\end{align*}  
$$  

정리하면 다음과 같은 식이 된다.  

$$ \therefore ~~ \hat{\sigma}^2 = \frac{1}{n-1} \sum (\hat{e}_i^2) $$  

즉 기댓값이 $\sigma^2$이 되는 불편추정량 ~~$\hat{\sigma^2}$~~은 ~~$\frac{1}{n-1} \sum (\hat{e}_i^2)$~~이라는 것이다.  

<br/>
 
![image](https://github.com/StatPage/blog-images/assets/61931924/a32542ac-ad71-4376-a656-3d32a08cbc86)

### 모평균 $\mu$를 알고 있을 때

그럼 이제 어려운 과정을 잘 넘어왔으니까 쉬운 과정인 모평균 $\mu$를 알고 있을 때를 유도해보자. 유도 과정에서 맨 처음 식에서 우리는 $\mu$를 모르기 때문에 $\hat{\mu}$를 식에서 빼고 더했었다. 그러나 이제는 그럴 필요가 없게 됐으니 식을 편하게 풀면 된다.  

$$\begin{align*}  
n \sigma^2 = E( \sum e_i^2 ) &= E(\sum (y_i - \mu)^2)\\  
\iff ~~ \sigma^2 &= E ( \frac{ \sum (y_i - \mu)^2 }{ n })\\  
\therefore ~~ \hat{\sigma}^2 &= \frac{ \sum (y_i - \mu)^2 }{ n }  
\end {align*}$$  

물론 모평균을 알고 있으니 처음부터 편차의 제곱 평균을 구하면 되긴 한다. 그렇지만 estimator가 불편추정량인 것을 보여주는 과정에서 어떤 차이가 있으며 이를 통해 식에 대한 이해를 높였으면 하는 바램에 정리해봤다.  

## 방정식의 의미

### 식1: $Var(\hat{\mu}) = \frac{\sigma^2}{n}$

앞서 분산의 estimator가 불편추정량임을 유도하는 과정에서 ~~$Var(\hat{\mu}) = \frac{\sigma^2}{n}$~~ 임을 언급했는데 이에 대해서 한 번 생각해보자. 책에서는 다음과 같은 명제의 의미를 숙지하라고 한다.


> 모집단의 분포가 넓으면 $\hat{\mu}$이 취할 수 있는 범위도 넓어진다.  
> 표본의 크기(sample size)가 작으면 $\hat{\mu}$가 취할 수 있는 범위는 넓어진다.

   
1번은 모집단의 분산 자체가 큰 경우에는 그만큼 estimator의 범위가 넓어질 수 있다는 얘기인데 값이 그만큼 변동을 많이 한다는 것이니 예측 혹은 정확한 분석을 하고 싶은 사람의 입장에서는 선호되는 현상은 아닐 것이다.  
   
2번 같은 경우에는 맨 처음에 언급했듯이 데이터를 많이 얻으면 얻을수록 하나의 값으로 수렴(변동성$\downarrow$)하는 것을 의미하며 그 반대인 데이터가 적으면 그만큼 ~~$\hat{\mu}$~~가 다양한 값이 나올 것이란 얘기다.  
 

### 식2: $\hat{\sigma}^2 = \frac{1}{n-1} \sum (\hat{e}_i^2)$

모평균 $\mu$를 모를 때 분모 자리에 $n$ 대신 $n-1$이 들어간다는 것은 무엇을 의미할까?  
책에서는 불확실성이 증가했다, 라고 한다. 왜냐? $\mu$를 모르기에 정확한 $e$를 구할 수 없기에 $\hat{\mu}$로 $\hat{e}$를 추정하고 $\hat{\sigma}$를 추정하기 때문이다. 불편추정량이 되기 위해 분산의 추정량을 유도함으로써 식을 얻을 수도 있지만 책에서 언급하는 직관으로 접근하는 방식 또한 현실 세계에서 응용하고 해석하기에 좋은 도구가 될 것 같다는 생각을 한다.  



# 데이터 사이언스를 위한 회귀분석 정리 3편: 분포에서 구간추정까지

김창진 교수님의 계량경제학 강의노트를 정리하면 나름대로 이해와 스토리에 맞게끔 선별해서 정리를 하고 있는 상황이다. 이 강의노트가 끝나면 본격적으로 다른 강의 노트를 가져오면서 온갖 테스트와 재밌는 내용을 추가해볼까 하는데 지금은 기초 이론을 탄탄히 정리하고 있다. 워낙 내공이 부족하기에 나의 빈 칸을 많이 확인하고 있는 중이다. 심지어 이렇게 올린 글에도 잘못되거나 부족한 부분이 있을 것이다... 그래도 빈 칸도 채우고 잘못된 건 고치면서 하다보면 언젠가는 좀 괜찮아지는 수준이 되지 않을까 생각중이다.

지금까지 가정을 바탕으로 데이터의 평균과 분산에 대해 모형을 세우고 이 추정량 estimator가 맞는 공식인지 기댓값과 분산에 대해 살펴봤다. 덤으로 그 공식들의 의미까지 한 번 언급해봤다.


> 추정량의 기댓값과 분산을 구한다는 건 무슨 의미일까?


이제는 추정량의 기댓값과 분산을 구하다는 사실에서 추정량 또한 불확실성을 가지고 있으며 결국은 분포를 따른다는 사실을 알게 됐다.

지금부터 우리는 분포에 대해서 잘 이해해야 하는 상황에 놓였다. 분포를 잘 이해해야 내가 세운 공식(모델)이 맞는 공식인지 확인할 수 있으며 하물며 분포의 모양을 확인해 봐야 하는 상황이 생길 수도 있기 때문이다. 앞에서 분포 모양으로 보여줬던 것들은 기본적으로 다 정규분포를 바탕으로 한 것이지 이게 균등 분포나, 감마 분포, 포아송 분포가 될 수 있는 상황도 고려해야 한다는 것이다.

<br/>

![image](https://github.com/StatPage/blog-images/assets/61931924/5bc403e4-6080-49ec-8c61-dc414918a476){: .align-center}

## 분포 이론

분포에 대해 공부하려면 `표본공간`, `확률변수`, `모집단`, `표본` 등의 개념에 대해서 이해하고 친숙해질 필요가 있다. 하지만 이 글에서 일일이 정리할 필요는 없다고 생각한다. 전 세계에 통계학과 확률론 관련하여 얼마나 좋은 강의와 자료가 넘쳐나는데 이건 각자 맞는 자료를 찾아보고 공부하자.

### 이산확률변수(discrete)와 연속확률변수(continuous)

우선 데이터가 어떤 종류이냐에 따라 성질이 달라질 수 있기 때문에 '이산형'과 '연속형'에 대해 보도록 하겠다.

-   이산확률변수: 어떤 확률변수가 취할 수 있는 가능한 값의 개수가 유한. ex) 주사위
-   연속확률변수: 어떤 확률 변수가 취할 수 있는 가능한 값의 개수가 무한대 일 때

### 이산확률변수

Probability distribution function

$$ f(x) = Pr(X=x) $$

확률변수 $X$가 숫자 x일 확률의 함수

Cumulative distribution function

$$ F(x) = Pr(X \le x)$$

확률변수 $X$가 숫자 $x$보다 작거나 같을 확률의 함수

### 연속확률변수

연속확률변수는 이산확률변수와 다르게 특정한 한 값이 나올 확률이 너무 작게 나온다. 책에 나온 예제 말고 하나의 예시를 들자면 타이머를 잴 때 타이머가 0.00000000000000001초까지 잴 수 있다면 내가 정확히 5.00000000000000000초를 잴 확률은 거의 0이다. 

$$Pr(X=x) = 0 ~~ \forall x$$

그렇기 때문에 이산확률변수의 'probability distribution function'이 아니라 'Probability density function'이 쓰인다. 분포 distribution에서 밀도 density로 성질이 바뀐 만큼 함수의 그래프에서 이제 중요한 것은 `높이`가 아니라 `넓이`가 되었다.


![image](https://github.com/StatPage/blog-images/assets/61931924/600b54b7-0b4e-42fd-8465-e6522e7b085a){: .align-center}{: width="75%" height="75%"}

이산확률변수처럼 연속확률변수도 누적 함수 cumulative function이 존재할 것이다. 단 cumulative density function이라고 할 것이다.

$$ 
\begin{align*}   
F(x) &= Pr(X \le x)\\  
&= \int_{-\int}^x f(x) dx  
\end{align*}
$$


> 또 하나 생각해 볼 수 있는 지점은 확률 밀도 함수 $f(x)$는 무엇을 의미하는지다. 누적 밀도 함수 $F(x)$가 넓이를 의미한다면 모든 확률 $f(x)$를 다 더해서 $F(x)$를 구하는 것이니까 찰나의 순간으로 짤라서 보면 $f(x)$는 $F(x)$가 얼만큼 변하는지 ~~변화~~를 보여주고 있을 것이다.  
>   
> 즉, $f(x)$는 넓이를 나타내는 $F(x)$에서 미분한 결과인 접선의 기울기이며 변화율인 것이다.


## 표준정규분포

이제 데이터 종류에 따라 함수의 종류가 어떤지 훑어봤으므로 가장 많이 활용되는 분포들에 대해서 살펴보자. 역시 세상에서 가장 많이 관측되는 분포는 아무래도 `정규분포`일 것이다. 하지만 정규 분포가 자주 관측된다고 해도 좋은 일은 아니다. 왜냐? 모든 분포의 평균과 분산이 동일하지 않을 것이기 때문이다. 


> 그게 뭐가 문젠데?


문제다. 위에서 본 확률 밀도 함수는 평균과 분산에 따라 그 종류가 달라지며 우리가 계산을 하기 위해서는 그 모든 분포에 대해 적분을 하나하나 다 따로 해줘야 하는 것이다.

그러한 불편함을 덜어주기 위해 평균 $0$, 분산 $1$인 표준정규분포의 모든 적분 계산을 해두고, 이를 활용할 것이다. 다음은 각각의 모든 정규 분포를 평균과 분산을 $0$과 $1$로 만들어주는 것이다. 이러한 과정을 `표준화`라고 한다. 식으로 표현하면 다음과 같다.

$$
\begin{align*}  
W &\sim N(\mu, \sigma^2)\\  
W - \mu &\sim N(0, \sigma^2)\\  
\frac{W - \mu}{\sigma} = Z &\sim N(0,1)  
\end{align*}
$$

<br/>

![image](https://github.com/StatPage/blog-images/assets/61931924/a82ffe6c-378b-4e88-861a-935accfe5dc3){: .align-center}{: width="75%" height="75%"}

## 점추정과 구간추정

우리는 데이터에 대해서 잘 모른다. 그렇기 때문에 가정을 바탕으로 한 모형을 세우고 공식을 세우고(estimator) 이를 검증하고 검증한 결과 또한 맞는지 알기 위해 분포에 대해 알아보고 있다. 다른 분포들에 대해서도 알아보기 전에 한 번 추정에 대해서 살펴보려고 한다. **추정에 대한 이야기가 뒤에 나오는 카이제곱 분포와 T 분포에도 연결**이 되기 때문이다.

덧붙이자면 책에서는 여기부터가 진짜 통계학이라고 교수님께서 언급하신 만큼 중요한 부분이다.


> 점추정은 무엇일까? 하나의 값으로 추정한 것이다.  
> 그렇다면 구간추정은? 구간으로 추정한 것이다.


당연하게도 우리는 모집단의 평균 ~~$\mu$~~와 분산 ~~$\sigma^2$~~를 몰랐기 때문에 이에 대해서 추정량 ~~$\hat{\mu}$~~, ~~$\hat{\sigma^2}$~~를 구한다. 그런데 이 값들도 불확실성을 내포하고 있기에 기댓값과 분산을 통해서 성질을 파악했었다. ~~$\bar{y}$~~를 예로 살펴보자.

$$ \bar{y} = \frac{1}{n} \sum y_i \sim N(\mu, \frac{\sigma^2}{n}) $$

기본적으로 추정량(여기서 ~~$\bar{y}$~~)은 데이터(여기서 ~~$y_i$~~)로 계산된다. 그리고 우리는 아직 데이터의 정확한 값을 알지 못하기 때문에 이를 확률변수라고 지칭한다. 확률변수는 분포를 가진다. 그렇기에 추정량(~~$\bar{y}$~~) 또한 분포를 가진다.

즉 우리의 추정에는 불확실성이 존재하기 때문에 이를 감안하여 하나의 숫자로 추정하는 점추정에서 불확실성을 포함하여 모수가 포함되는 비율이 몇 %인 구간을 추정해주는 구간추정까지 나아가는 것이다. 그리고 이 때 식에 있는 ~~$\frac{\sigma^2}{n}$~~가 쓰이게 된다. 그렇다면 이러한 구간(`신뢰구간`)은 $-\infty$에서 $\infty$로 되어있으면 의미가 없을 것이다. 그렇기에 가능한 구간이 좁고, 모수를 포함하는 확률은 높은 것이 좋을 것이다. 

(모수를 포함하는 확률 또한 표준정규분포의 적분 결과값들이 활용된다.)

<br/>

# 데이터 사이언스를 위한 회귀분석 정리 4편: 중심극한정리에서 t분포까지

모집단에 관한 모형을 세울 때 언급하지 않았던 가정 하나를 먼저 짚어보고 가겠다. 이 가정을 정리해야 `CLT`를 이해해서 `t 분포`까지 스토리를 이어갈 수 있다.  
 

## 가정 추가

우선 이전에 세워둔 모형은 아래와 같았다.  

$$ y_i = \mu + e_i $$  

where $E(e_i) = 0~~ \forall i$, $E(e_i^2) = \sigma^2~~ \forall i$  
   
여기에 추가되는 가정은 아래와 같다.  

$$ E(e_i \cdot e_j) = 0~~ \forall i \neq j $$  


> 이 식은 뭘 의미할까?


식 그대로 설명을 해보자면, $i$번째 추출과 $j$번째 추출이 상호 독립적이어야 한다는 것이다. 직관적으로 예시를 들자면, 동전을 굴려서 앞면과 뒷면이 나올 확률은 각각 $\frac{1}{2}$이다. 그런데 전에 앞면이 나왔다고 해서 그 다음 동전을 굴릴 때 앞면이나 뒷면이 나올 확률이 달라지면 안 된다는 것이다.  
   
모형에서 불확실한 요소 ~~$e_i$~~는 말 그대로 불확실한(random) 요소 그 자체로 남아있어야지 ~~$e_i$~~와 ~~$e_j$~~가 서로 관련이 있으면 안 된다. 서로 관련됐다는 것은 $i$번째 값으로 인해서 $j$가 변한다는 것이고 ~~$e_i$~~가 앞에 나온 값들에 의해서 확률이 달라진다면 데이터가 순수하게 random으로 추출된 게 아니라는 것이고 **인위(구조)적인 요소가 데이터에 반영**되었기 때문에 이를 바탕으로 분포를 정확히 추정할 수 없게 된다.  
 

> 그게 뭐가 문제일까?


우리가 분포를 다루는 이유는,  
 

> 순수한 랜덤 데이터가 모이면 따르는 모양 혹은 성질이 있기에 그 사실을 바탕으로 데이터를 분석하면 유용한 결과를 얻을 수 있기 때문이다.

   
평균과 분산을 구해서 추정을 할 때도 마찬가지로 이 분포의 정보를 바탕으로 구한다. 그런데 우리가 추정한 분포가 사실 random이 아닌 평균 $\mu$와 같이 인위적인 구조가 있다면 그건 모형이 맞는지 체크하는 건 고사하고 잘못된 분석 결과를 내놓을 수 있다.  
(가정에서 평균 $\mu$같이 인위적인 구조가 남았는지 파악하는 가정은 ~~$E(e) = 0$~~)  


![image](https://github.com/StatPage/blog-images/assets/61931924/49f22c04-c9db-44a2-b874-dff9c6fa46ff){: .align-center}

지금 계속 얘기하고 있는 것은 데이터 ~~$y$~~를 추출할 때마다 왼쪽에 있는 그래프와 같이 동일한 확률 분포 아래에서 추출해야 한다는 것이다. 오른쪽 이미지를 봐보자. 만약 지금 내가 얻은 데이터 ~~$y_1$~~이랑 다음에 뽑는 ~~$y_2$~~는 뽑을 때마다 서로 동일한 확률 분포 아래에서 random한 값이 나와야 한다. ~~$y_1$~~을 ~~$x$~~축으로 보고 ~~$y_2$~~를 ~~$y$~~ 축으로 생각해보자.  
   
서로 확률에 영향을 안 주면 오른쪽 이미지에서 ~~$c=0$~~인 그래프다. ~~$y_1$~~이 무슨 값이 나오든 말든 ~~$y_2$~~는 왼쪽의 동일한 분포 아래에서 임의의 값으로 나온는 것이다.  
   
그런데 ~~$c=0.99995$~~를 보자. $y = 1x$ 그래프 마냥 ~~$y_2 = y_1$~~이 된 그래프가 보이는데 이런 상황이면 ~~$y_2$~~는 ~~$y_1$~~에 나온 값에 상관없이 왼쪽 이미지에 있는 확률 분포 아래서 임의 값이 나올까? 절대 아니다. ~~$y_1$~~이 $0.5$가 나오면 ~~$y_2$~~는 $0.5$에 유사한 값이 나올 것이고 ~~$y_1$~~이 $-1.5$가 나오면 ~~$y_2$~~도 거의 $-1.5$에 가까운 값이 나올 것이다.  
   
이러면 안 된다. 우리는 왼쪽 이미지에 있는 분포에 대해서 알고 싶은 상황이다. 그러니까 **똑같은 분포 아래서 똑같은 확률로 많은 데이터를 얻어야 하는데(random experiment), $y_1 = y_2$같은 관계가 형성이 되어 있으면 $y_1$은 왼쪽 이미지에 있는 분포를 따른다고 해도 다른 데이터인$y_2$, $y_3$, ..., $y_n$은 거의 $y_1$의 값에 가깝게 나올 것이기 이 데이터들은 $y_1$의 복제품이 되는 것이다.**  
 

> 그러면 왼쪽 이미지에 있는 (우리가 알고 싶은) 분포에 관한 정보를 얻을 수가 없다.

   
우리가 이 때까지 평균과 분산을 분석한 과정 아래에는 구조(확정)적인 요소가 거의 제거된 순수한 random(불확정) ~~$e$~~를 모으면 분포를 따른다는 믿음이 있었다. 그렇기 때문에 정답만 찾아가는 과정이었다. 그런데 위와 같은 상황처럼 데이터가 서로 영향을 줘서 분포에 대한 도움이 되는 정보를 얻지 못하고 분포 또한 잘못 측정했다? 그러면 우리가 찾은 결과 또한 문제가 있다고 걱정해야 한다.  
   
위와 같은 이유로 기본적으로 모형을 세울 때는 이 가정 $E(e_i \cdot e_j) = 0~~ \forall i \neq j$까지 필요하다고 얘기할 수 있다.  
 
![image](https://github.com/StatPage/blog-images/assets/61931924/e52737c3-1a9e-496c-a0d0-136e9c0e2ab1){: .align-center}{: width="75%"}

## $y_i$의 분포

위의 가정을 구구절절 이야기 한 이유는 결국 아래의 공식을 쓰고 싶었기 때문이다.  

$$ y_i \sim iid N(\mu, \sigma^2) $$  

이걸 바탕으로 ~~$y_i$~~의 평균 estimator ~~$\bar{y}$~~의 분포를 알 수 있으며  
(모든 데이터 ~~$y_i$~~가 동일한 분포의 정보를 지니고 있고, 서로 영향을 안주니까 순수한 random 추출이기 때문이다.)  

$$ \bar{y} \sim N(\mu, \frac{\sigma^2}{n}) $$  

이를 표준정규분포로 만들어서 미리 계산한 적분값으로 테스트를 할 수 있게 됐다.  

$$ Z = \frac{ \bar{y} - \mu }{ \sqrt{ \frac{\sigma^2}{n} } } \sim N(0, 1) $$  

이를 바탕으로 위에서 설명한 구간추정(신뢰 구간)까지 제시한 것이다. 

<br/>

### 정규분포가 아니라면?

가장 근본적인 걸 건드려보자.   

$$ y_i \sim iid N(\mu, \sigma^2) $$  


> 정규분포를 따르는 게 당연한 걸까? 세상의 많은 데이터가 정규분포를 따르기는 했다.  
> 하지만 모든 데이터가 정규분포를 따를까? 

   
당연히 아닐 것이다. 그리고 데이터가 어떤 분포를 따르고 있는지조차 모를 수도 있다.  
분포를 모르면 우리가 구한 평균의 estimator $\bar{y}$가 어떤 분포를 따르는지 모르고 구간추정까지 할 수 없게 된다.  
   
이 문제는 어떻게 해결해야 할까?  

<br/> 

### 분포를 몰라도 괜찮아 우리한텐 CLT가 있어

이제는 분포를 모르는 상황이 됐다.  
   
분포는 몰라도 임의로 데이터를 추출해서 표본 평균을 구하면 아래까지는 가정할 수 있을 것이다.  

$$ \begin{align*} \bar{y} &= \frac{1}{n} \sum y_i \\ \bar{y} &\sim (\mu, \sigma^2) \end{align*} $$  

하지만 분포를 모르니 정확한 추정을 할 수 없다는 한계가 있다.  
그 때 이 문제를 (저속한 표현으로) 기깔나게 해결해주는 이론이 `중심극한정리(CLT: Central Limit Theorem)`이다.   
   
중심극한정리 CLT에 의하면  
 

> 데이터 수 $n$이 무한대에 가까워질수록 $\bar{y}$의 분포도 정규분포에 가까워진다


고 한다.   

$$ \bar{y} \sim N(\mu, \frac{ \sigma^2 }{ n }) ~~ \text{as } n \rightarrow \infty $$  

사견을 하나 달자면 ~~$\bar{y}$~~를 계산하는 데이터(표본) 수에 따라 분포가 결정된다는 것인데 이에 관한 유도까지는 책에는 없고 개인적으로 공부한 내용들을 수식만 정리해서 블로그에 한 번 올려봐야 겠다. 나에게는 ~~$ \bar{y} \overset{d}{\rightarrow} N(\mu, \frac{ \sigma^2 }{ n }) $~~이 더 익숙한데 이렇게 표현하려면 다른 내용들을 조금 더 추가해야 겠다.  
   
이제 데이터 수만 충분하다면(보통 30개 이상으로 언급) 우리는 다음과 같은 식으로 점추정과 구간추정을 할 수 있게 된다.  
(물론 $\sigma^2$ 또한 어떤 분포를 따르는지 고려해야 하지만 가장 기본적인 결과를 보여주기 위해서 $\sigma^2$은 아는 값이라고 가정하고 결과를 보여준다.)  

$$ \bar{y} \sim N(\mu, \frac{ \sigma^2 }{ n }) $$  

그리고 이를 표준화하면 아래 식이 된다.  

$$ Z = \frac{ \bar{y} - \mu }{ \sqrt{ \frac{ \sigma^2 }{ n } } } \sim N( 0, 1) $$  

앞에서도 언급했듯이 우리는 보통 모집단의 분산 $\sigma^2$을 모른다. 그러니 분산의 estimator $\hat{\sigma}^2$를 구해서 써야 한다. 이걸 식에 반영해서 정리하면 다음과 같이 된다.  

$$  Z = \frac{ \bar{y} - \mu }{ \sqrt{ \frac{ \hat{\sigma}^2 }{ n } } } \sim N( 0, 1) $$

~~$\sigma^2$~~ 대신 ~~$\hat{\sigma}^2$~~을 썼다는 건 불확실성이 증가한다는 것을 의미한다. 이로 인해 분포의 분산이 표준정규분포의 분산인 1보다 커졌을테니 더 이상 변수 $Z$가 표준정규분포를 따른다고 할 수 없게 됐다. 앞으로는 이 변수를 $Z$라고 쓰지 않고 다른 분포를 따르는 확률 변수로서 $T$라고 쓰겠다.  
 

> 뭐야? 아까는  CLT가 데이터 수가 증가하면서 $\bar{y}$가 정규분포를 따른다고 했잖아?

   
맞다. 이번에도 데이터 수가 증가하면서 정규분포가 될 것이다. 하지만 똑같은 데이터 수($n$)에서 보다 분산이 더 큰 분포가 될 것이다. 그리고 위에서 언급한 것이랑 반대로 데이터 수가 충분하지 않다면 정규분포가 아닌 다른 분포를 따를 것이다.   
   
어떤 분포를 따르는지 확인하기 위해서는 추가적인 분포 `카이제곱분포`를 알 필요가 있다.  

<br/>

![image](https://github.com/StatPage/blog-images/assets/61931924/754c90bf-0edb-4ba8-83f9-dd69faac44da){: .align-center}

## 카이제곱분포 Chi-square Distribution

위 이미지 캡션에 가져온 글을 보면 정규분포의 표본 분산의 분포로서 카이제곱분포를 [Friedrich Robert Helmert](https://en.wikipedia.org/wiki/Friedrich_Robert_Helmert)라는 사람이 발견했다는 것을 알 수 있다.  
(우리가 흔히 알고 있는 스튜던트 $t$ 분포 또한 저 분이 이미 발견해놓은 것이라고 하는데 영어가 아니라 독일어를 쓰는 사람이다보니 많이 알려지지 않았고 후에 영어를 사용하는 윌리엄 고셋이 발견하여 그의 필명(student)으로 분포의 이름이 널리 알려졌다고 한다.)  
   
앞에서 모평균 $\mu$를 모를 때 분산의 불편추정량은 $ \hat{\sigma}^2 = \frac{ \sum (y_i - \mu)^2 }{ n-1 }$이었다.  
   
식에는 변수인 ~~$y_i$~~가 포함되어 있으므로 분산의 불편추정량 또한 변수이며 분포를 따를 수 있다는 것을 짐작할 수 있다. 그럼 어떤 분포를 따를까? 특히나 이 식은 제곱에 관한 식이기에 정규분포를 그대로 쓸 수는 없을 것이다.  
   
이 때까지 정리해온 것을 바탕으로 시작을 해보자. $\frac{ \sum (y_i - \mu)^2 }{ n-1 }$에서 위의 항만 따로 보면 표준정규분포를 따르는 식으로 만들 수 있다. (~~$\sigma^2$~~은 모르지만 모집단의 분산이라는 가정으로 전개. 몰라도 분모, 분자 곱 1)  

$$  
\begin{align*}  
\hat{\sigma}^2 &=  \sigma^2 \frac{ \sum \left( \frac{ y_i - \mu }{ \sigma } \right)^2 }{ n-1 }\\  
\frac{ y_i - \mu }{\sigma } &\sim N( 0, 1)  
\end{align*}  
$$  

이제 분산의 불편추정량 안에 표준정규분포의 변수가 제곱합이라는 형태로 있다는 것을 알 수 있다. 우리는 저 변수의 분포만 알면 된다. 나머지 값들은 변수가 아니기 때문이다. 그리고 표준정규분포의 제곱합이 따르는 분포가 바로 `카이제곱분포(Chi-square Distribution)`다.  

![image](https://github.com/StatPage/blog-images/assets/61931924/f95d8e2c-edce-4761-9940-d5f073031b73){: .align-center}

카이제곱분포를 따를 때 수식은 다음과 같다.  

$$  
\begin{align*}  
Z &\sim N(0,1)\\  
B = Z_1^2+Z_2^2 + \cdots + Z_k^2 &\sim \chi^2(k) \text{  : Chi-square Distribution with degrees of freedom k}  
\end{align*}  
$$  

당연히 카이제곱분포는 자유도에 따라 분포의 모양이 변한다. 표준정규분포를 몇 개까지 제곱해서 더하는지가 자유도에 따라 결정되기 때문이다. 마치 이항분포에서 정규분포로 근사하는 것처럼 말이다. 책에 있는 설명을 붙여보자면 정규분포를 제곱한 숫자들이 더 많아질수록 분포가 넓어진다고 할 수 있다. 그만큼 조합이 많아지고 흔한 조합이 발생할 확률은 높아지는 것이니까.   
   
카이제곱분포에서 조금 특이한 점은 평균이 자유도 $k$이고 분산은 평균의 두 배인 $2k$라고 한다.   


![image](https://github.com/StatPage/blog-images/assets/61931924/36fc9256-9dca-4c66-90ac-03b61ecca980)

## CLT와 t분포

다시 위의 식으로 돌아가보자. 우리는 CLT에서 모집단의 분산 ~~$\sigma^2$~~을 몰랐기 때문에 더 이상 ~~$Z = \frac{ \bar{y} - \mu }{ \sqrt{ \frac{ \hat{\sigma}^2 }{ n } } } $~~가 표준정규분포를 따르지 않는다고 했다. 그래서 $Z$라고 쓰지 않고 ~~$T$~~라고 썼는데, 조금 더 설명해보자면 **우리가 다뤄야 할 변수가 $\mu$ 하나에서 $\sigma$가 추가된 두 개로 늘어난 것**이다. 그래서 $T$는 두 개의 분산을 동시에 고려해야 하는 변수가 된 것이다.  
   
이런 필요성에 의해서 정규분포의 분산이 따르는 분포를 학자들이 찾게 됐고 그 결과로 우리가 현재 카이제곱분포를 공부하게 된 것 같다. 우리가 앞서 공부한 표준정규분포와 카이제곱분포는 CLT에서 분산을 모르는 경우에 변수에 활용되며 둘의 비율로 구성된 변수 ~~$T$~~는 이제 ~~$t$~~ 분포를 따른다고 표현할 수 있다.  
   
식을 한 번 써보기 전에 유념해야 할 사항으로 표준정규분포를 따르는 변수 $Z$와 카이제곱분포를 따르는 변수 $B$는 서로 독립이다. 즉 서로의 확률에 영향을 끼치지 않는다.  

$$    
\begin{align*}  
T &= \frac{ \bar{y} - \mu }{ \sqrt{ \frac{ \hat{\sigma}^2 }{ n } } }\\  
&= \frac{ \left( \frac{ y - \mu }{ \sigma } \right) }{ \sqrt{ \frac{ \sum \left( \frac{ y_i - \mu }{ \sigma } \right)^2 }{ n (n - 1) } } }\\
&= \frac{ \frac{ \bar{y} - \mu }{ \sigma / \sqrt{ n } } }{ \sqrt{ B }{ n-1 } }, \quad B \sim \chi^2(n-1)\\
&= \frac{ Z }{ \sqrt{ \frac{ B }{ n-1 } } },\quad Z \sim N(0, 1)\\  
&\sim T(n-1)  
\end{align*}  
$$  

책에서는 이를 서로 독립인 표준정규분포와 카이제곱분포의 적절한 비율이라고 표현했다. 왜냐하면 ~~$B$~~는 표준정규분포 ~~$Z$~~의 제곱합이 ~~$k$~~번 더해졌기 때문이다. 이 차이를 없애주기 위해서 ~~$(n-1)$~~로 나눠주고, 제곱합이니까 루트를 씌워 동일한 스케일의 비율로 해석할 수도 있는 것 같다.  

![image](https://github.com/StatPage/blog-images/assets/61931924/02618be1-39db-41cc-91b9-9d5862316e95)


그림을 보면 ~~$n$~~은 자유도를 의미하는데 결국 자유도가 크면 클수록 표준정규분포에 가까워진다고 볼 수 있다. 그걸 식으로 표현하면  

$$ Var(T) = 1~~ \text{as } n \rightarrow \infty $$  

<br/>

> 왜 이렇게 될까?

$t$분포의 기댓값과 분산을 구하면 다음과 같기 때문이다. (왜 이렇게 나오는지 궁금한 사람들은 직접 구해봐도 좋은 것 같다.)

-   $E( T ) = 0$
-   $Var( T ) = \frac{ k }{ k - 2 } \rightarrow 1 ~~\text{as } k \rightarrow \infty$

<br/>

그래프에서 알 수 있듯이 ~~$t$~~분포는 자유도 $k$가 $30$이 되기 전에는 정규분포와 같지 않은 모양으로 있다가 자유도가 30개가 된 순간 정규분포와 같은 모습이 돼기 시작한다. 그래서 보통 데이터 개수 30개 이상부터 정규분포로 근사한다고 이야기하는 구나,라고 생각해 볼 수도 있겠다.

> $t$분포의 분산에서 보면 결국은 표준정규 분포의 분산인 1보다 항상 크기에 (자유도 $k$가 무한대로 가도 결국 1로 수렴할 뿐 1이 되진 않으니까) $t$ 분포는 표준정규분포에 비해서 상대적으로 큰 불확실성을 반영한 분포이다.


우리는 모집단의 분산인 ~~$\sigma^2$~~을 모르니까 불확실성이 커지는 것이 당연한 것이고 이러한 사실이 반영된 분포($t$ 분포)가 찾아내어 활용하고 있기 때문에 이 내용이 중요하다고 생각할 수 있다.  
(마치 효용함수의 log처럼)  


## 참고 사항

### iid

추가 예정

### 자유도

데이터 개수는 총 $n$ 개인데 왜 `카이제곱분포`와 `t 분포`는 자유도가 ~~$n-1$~~개가 될까?  
   
상황을 구분해서 보자면 우리가 모집단의 평균 $\mu$를 추정할 때는 자유도가 $n$이 된다. 그런데 모르는 상황이면 $ \hat{\mu}$를 추정해서 $\hat{e}$를 구해야 한다. 표본으로 뽑은 데이터 $y_i$ 값들의 합인 $\sum y_i = c$로 고정되어 있다는 것이다. 그러면 $n$ 개의 데이터가 있더라도 $n-1$ 개까지는 데이터 값이 랜덤하게 바뀔 수야 있지만 마지막 데이터 $y_n$은 전체합 $c$에서 $\sum_{i=1}^{n-1}y_i$를 뺀 값(linear dependent)이 되기에 독립적인 정보가 될 수 없다.  
   
(글의 첫 부분에서도 다른 데이터에 상관 없이 동일한 확률 아래서 random으로 뽑혀야 한다고 엄청 길게 썼다. 여기서도 마찬가지로 하나의 데이터가 독립적이지 않고 다른 데이터들의 조합으로 종속되어버렸으니 분포에 관한 정보를 담은 유의미한 정보가 되지 못하게 됐다.)  

<br/>

> 그러니까 자유도가 하나 줄어든 것이다.  
> 자유도가 하나 줄어들면 무엇이 안 좋을까?  

분포의 정보를 담고 있는 데이터 하나를 잃게 된 것이기 분포에 대한 정확한 추정을 상대적으로 못하게 된 것. 평균의 estimator의 분산을 생각해보면  

$$ Var(\bar{y}) = \frac{ \sigma^2 }{ n } $$  

분모에 있는 n의 값이 10에서 9가 된다면 분모가 더 작아진 것이기 때문에 분산이 커진다고 할 수 있다. 그렇게 되면 구간추정을 할 때도 신뢰구간의 길이가 넓어지기 때문에 추정에 대한 신뢰성이 상대적으로 낮아지는 것이다.  
 

### 분산이 크면

우리는 좀 더 넓게 퍼진 분포를 떠올린다. 넓게 퍼졌다는 의미는 평균을 중심으로 잘 뭉쳐져 있지 않고 이상치, 극단값들이 상대적으로 많이 있다는 의미다.  
   
![image](https://github.com/StatPage/blog-images/assets/61931924/1904dff9-607c-4a80-bc72-c48328f56573){: .align-center}{: height="50%"}

### Reference

김창진 계량경제학 I 강의노트
